# RocketMQ 日志异步批量写入 ES 方案

> 目标：消费端收到多类型日志（每条消息是 `List<Log>`，1~100 条），按类型分队列，异步批量（每次最多 200 条）写入 Elasticsearch，提高整体性能与稳定性。

---

## 一、整体架构设计

### 1.1 数据流向总览

```text
          ┌────────────────────────────┐
          │        RocketMQ 集群       │
          └────────────┬──────────────┘
                       │  消费 (List<Log>)
                       v
            ┌────────────────────────┐
            │   Consumer(并发消费)   │
            └────────────┬──────────┘
                         │  按类型拆分
                         v
        ┌────────────────────────────────────┐
        │      内部多队列缓冲层 (内存)       │
        │  Map<LogType, BlockingQueue>      │
        └───────┬───────────┬──────────────┘
                │           │
       ┌────────v───┐ ┌─────v────────┐
       │ Worker A   │ │   Worker B   │  …… 每种日志类型 1 个 Worker
       │ (type=A)   │ │  (type=B)    │
       └─────┬──────┘ └─────┬────────┘
             │  批量(≤200)  │
             v              v
        ┌─────────────────────────────────┐
        │       ES Bulk API 写入层       │
        └─────────────────────────────────┘
```

**核心思路：**
- RocketMQ 消费端只负责**拆分 + 入队**，快速返回，减少对 MQ 的反压。
- 进程内部维护一组按日志类型划分的阻塞队列，做**缓冲和削峰**。
- 为每种日志类型分配一个 Worker（核心线程），定时从队列中**批量拉取最多 200 条**，通过 ES Bulk API 写入。

---

## 二、队列与线程池设计

### 2.1 队列结构

```text
               Map<LogType, BlockingQueue<LogDoc>>
               ┌─────────────────────────────────┐
               │  typeA -> ArrayBlockingQueue   │  capacity = N
               │  typeB -> ArrayBlockingQueue   │
               │  typeC -> ArrayBlockingQueue   │
               └─────────────────────────────────┘
```

- 每种日志类型一个队列，保证：
  - 同类型日志**写 ES 顺序相对有序**（一个 Worker 对应一个类型）。
  - 不同类型互不影响：A 类型暴增不会堵死 B 类型。

**容量建议：**
- 使用 `ArrayBlockingQueue`，capacity 根据流量评估，例如：
  - `capacity = 200 * 30`（可缓冲 30 个批次）。
- 入队策略：
  - `put()`：队列满时**阻塞 RocketMQ 消费线程**，以反压方式保护系统。
  - 或 `offer(timeout)`：超时仍满则**打告警 + 统计丢弃数**，看业务是否容忍丢日志。

### 2.2 线程池结构

```text
          ScheduledThreadPoolExecutor
          (size = 日志类型数 or min(类型数, CPU*2))

              ┌───────────────┬───────────────┐
              │               │               │
        ┌─────v─────┐   ┌─────v─────┐   ┌─────v─────┐
        │ Worker A  │   │ Worker B  │   │ Worker C  │   ...
        │ type = A  │   │ type = B  │   │ type = C  │
        └───────────┘   └───────────┘   └───────────┘
```

- 每个日志类型对应一个 Worker 任务：
  - 使用 `ScheduledThreadPoolExecutor` 按固定周期调度（例如每 100ms 一次）。
  - 每次调度时，从对应队列中最多拉取 `batchSize = 200` 条日志，组装 BulkRequest 写 ES。
- 线程池大小：
  - 若日志类型较少（< 10），可基本 "1 类型 1 线程"。
  - 类型很多时，可限制为 `min(类型数, 2 * CPU 核数)`，冷门类型可合并到公共 Worker 中。

---

## 三、消费端处理与入队流程

### 3.1 RocketMQ 消费端处理逻辑

```text
RocketMQ Consumer 收到消息 (topic: log_topic)
message.body = List<LogRecord>   // 每条消息 1~100 个

for each LogRecord lr in list:
    LogType type = lr.getType();
    LogDoc  doc  = convertToEsDoc(lr);  // 转换成 ES 的文档结构

    BlockingQueue<LogDoc> q = queueMap.get(type);
    if (q == null) {
        // 懒加载：初始化该类型队列 + Worker（可选）
    }

    q.put(doc);  // 或 offer(timeout, TimeUnit.MILLISECONDS)
```

**要点：**
- 每条 RocketMQ 消息是一个 `List<LogRecord>`，长度 1~100。
  - 需要 **拆分** 为粒度为单条日志的 `LogDoc` 再入队。
- `convertToEsDoc` 中可以做：
  - 日志字段映射、补全公共字段（如 traceId、appName、env 等）。
  - 根据日志类型/业务线生成目标 ES index 名（如 `log_appA_error_2025-12-05`）。

---

## 四、Worker 批量写 ES 的逻辑

### 4.1 Worker 内部结构（单类型）

```text
Worker(type = A)

本地缓冲：List<LogDoc> localBuffer  (size <= 200)
触发条件：
  - 从队列成功取到 200 条；或
  - 定时任务到期但当前缓冲非空（例如每 100ms 调用一次）；
```

### 4.2 批量提取 & 写 ES 时序

```text
   ┌──────────────────Scheduled task (type=A)──────────────────┐
   │                                                          │
   │ 1. localBuffer.clear()                                   │
   │ 2. while localBuffer.size < 200:                         │
   │        doc = queue.poll(10ms)                            │
   │        if doc == null: break                             │
   │        localBuffer.add(doc)                              │
   │ 3. if localBuffer 非空:                                  │
   │        bulkRequest = buildBulk(localBuffer)              │
   │        esClient.bulk(bulkRequest)                        │
   │        处理失败重试 / 落盘 / 告警                         │
   │                                                          │
   └───────────────────────────────────────────────────────────┘
```

- 这样既能做到 **“凑够 200 条再写”**，又能保证低流量下**定时刷出**（不至于日志长时间滞留在内存）。
- `poll(10ms)` 可以保证在低流量下不会一直阻塞，给定时任务一个退出机会。

---

## 五、整体时序图

```text
RocketMQ         Consumer           Queue[typeA]           Worker[typeA]        ES
   |                |                     |                     |               |
   | msg(List)      |                     |                     |               |
   |--------------->|                     |                     |               |
   |                | 解析 List           |                     |               |
   |                | for each lr type=A  |                     |               |
   |                |-------------------->| put(lrA1)           |               |
   |                |-------------------->| put(lrA2)...        |               |
   |                |                     |                     |               |
   |                |                     |    poll(最多200)    |               |
   |                |                     |-------------------->| buildBulk     |
   |                |                     |                     |-------------->|
   |                |                     |                     |   Bulk index  |
   |                |                     |                     |<--------------|
   |                |                     |                     |  ok / fail    |
   |                |                     |                     |  重试 / 告警   |
```

---

## 六、关键参数与调优策略

### 6.1 批量大小 & 刷新间隔

- **批大小 `batchSize`**：默认 200
  - 大一些：提高 ES 吞吐，但单批出问题（失败重试）成本更高。
  - 小一些：降低延迟，但整体 QPS 能力下降。
- **调度周期 `flushIntervalMs`**：默认 50~200ms
  - 高流量时主要靠“攒满 200 条”触发；
  - 低流量时靠定时任务刷出零星日志，避免长时间滞留。

### 6.2 队列容量与背压策略

- **队列容量 `queueCapacity`**：防止堆内存被日志 OOM。
  - 可根据预估峰值：`capacity ≈ 峰值QPS * 可接受排队秒数 / batchSize`。
- **满时策略：**
  - 阻塞 `put()`：将压力回传到 RocketMQ Consumer，极端情况下**消费变慢但不丢日志**。
  - 限流+丢弃：`offer(timeout)` 超时丢弃，记录日志+指标+告警，适合对日志不 100% 可靠的场景。

### 6.3 线程数 & 类型分配

- 若日志类型数 `T` 较少：
  - `corePoolSize = T`，一类型一线程，结构清晰。
- 若 T 很多：
  - `corePoolSize = min(T, 2*CPU)`，
  - 冷门类型通过 **hash 分组**：

```text
Group0: typeA, typeC, typeF
Group1: typeB, typeD
...
```

  - 每个 Group 一个 Worker，队列可以按 `Map<Group, Queue>` 再做一层聚合。

---

## 七、错误处理与重试设计（简要）

### 7.1 Bulk 写 ES 的返回结果处理

- 对于每个 Bulk item 需要区分：
  - **成功**：正常结束；
  - **4xx（如 400/404/409 等）业务错误**：
    - 通常是 mapping 不匹配、字段类型错误、版本冲突等；
    - 建议：**记录到本地 error 日志或单独的失败索引**，不再重试。
  - **5xx 或网络超时等临时错误**：
    - 可以放入 `retryQueue`，按退避策略重试。

### 7.2 重试队列设计（可选）

```text
      +---------------------+
      |   retryQueue(typeA) |
      +----------+----------+
                 |
          ┌------v------┐
          | RetryWorker |
          └-------------┘
```

- `RetryWorker` 周期更长（如 5s / 30s）
- 支持最大重试次数，超过阈值写入死信存储（文件 / 专门的 ES index / MQ DLQ）。

---

## 八、与现有技术栈的集成建议

假设当前技术栈为 Spring Boot + RocketMQ + ES：

- **RocketMQ**：使用 Spring Cloud Stream 或 `rocketmq-spring`，消费端容器中注入 `LogDispatchService` 完成类型识别和入队。
- **ES 客户端**：
  - ES7 及以下：`RestHighLevelClient`；
  - ES8：官方 Java API Client；
  - 封装一个 `EsBulkService`，只提供 `bulkInsert(List<LogDoc>)` 对外接口，由该服务内部实现 BulkRequest 构造与失败处理。
- **配置化**：
  - `batchSize`、`flushIntervalMs`、`queueCapacity`、各类型索引前缀等，全部放在配置中心或配置文件中，支持动态调优。

---

## 九、小结

- 通过 **RocketMQ 消费拆分 + 按日志类型分队列 + 定时批量写 ES** 的模式：
  - 利用内存队列做缓冲，平滑流量波峰；
  - 使用 Bulk API 提升 ES 写入吞吐；
  - 通过按类型隔离队列与 Worker，避免单一类型日志撑爆全局；
  - 结合重试与告警机制，保证整体可用性和可观测性。

后续可以在此基础上继续演进：
- 引入统一指标（队列长度、批量耗时、ES 写入成功率等）上报到 Prometheus / Grafana；
- 根据实时指标动态调整批大小和刷盘间隔，实现自适应调优。

---

## 十、写入队列和从队列拉取的安全性保证

### 10.1 并发安全：为什么用阻塞队列

```text
多生产者 (Consumer 线程)  --->  BlockingQueue  --->  单消费者 (Worker 线程)
```

- `ArrayBlockingQueue` / `LinkedBlockingQueue` 本身是**线程安全**的：
  - 内部使用锁 + 条件变量保证 `put` / `take` / `poll` 的原子性；
  - 多个 RocketMQ 消费线程并发 `put` 不会出现“覆盖 / 丢失 / 读到脏数据”。
- 我们约定：
  - **只有 Consumer 负责写队列（生产），Worker 负责读队列（消费）**，不在其他线程直接操作队列。
  - Worker 自己维护的 `localBuffer` 只在该 Worker 线程内使用，不需要额外加锁。

### 10.2 ACK 时机：保证“至少一次”投递

为了在 MQ 与内部队列之间保证安全，需要明确 **ACK 的时机**：

```text
          ┌──────────── put 成功 ────────────┐
RocketMQ  |                                  v
消息 ---> Consumer 线程 ---> BlockingQueue  (入队成功) ---> ACK 给 MQ
          |                                     ^
          └──── put 失败 / 超时：不 ACK，等待重投 ─────┘
```

- **推荐做法：**
  - 只有当日志成功 `put` 进队列后，才向 RocketMQ 发送 ACK（消费成功）。
  - 如果队列满导致 `put`/`offer` 失败或超时：
    - 可以选择：
      - 不 ACK，让消息进入重试；
      - 或记录错误后按业务策略丢弃（日志业务容忍少量丢失时）。
- 这样可以保证：
  - **只要消息被 ACK，就一定已经进入队列，后续一定有机会被 Worker 处理。**

### 10.3 幂等写入：解决重复消费 / 重试导致的重复入库

因为 MQ 重试、网络抖动等原因，某条日志可能被**消费多次**或被 Worker **重试多次**，需要在 ES 侧做幂等：

- 为每条日志生成**全局唯一 id**，例如：
  - `esId = mqMessageId + "_" + indexInList`；
  - 或业务侧已有 traceId / logId。
- 在 BulkRequest 中显式设置 `_id = esId`：
  - 多次写入同一 `_id` 只会覆盖，不会产生重复文档；
  - 保证“**最终只保留一份**”。

```text
重复消费场景：

RocketMQ  重投 -> Consumer ---> Queue ---> Worker ---> ES(index, _id=K)
                              再次处理 ----^   (同一个 _id=K)

ES 中最终只有一条文档 (_id=K)
```

### 10.4 顺序安全：FIFO 队列 + 单 Worker

- 队列本身是 **FIFO（先入先出）**：
  - 同一类型的日志按入队顺序排队；
  - Worker 总是从队首批量 `poll`，不会打乱顺序。
- 每种日志类型使用**单个 Worker 线程**：
  - 避免同一类型在多个线程同时处理导致顺序混乱；
  - 如果需要进一步扩展吞吐，可按 shardKey 再细分队列（如 `typeA_shard0/1/2`），每个 shard 仍维持 FIFO + 单 Worker。

### 10.5 优雅关闭：确保队列中的数据不丢

在服务重启 / 下线时，需要保证队列中已入队但未写入 ES 的数据被处理完：

```text
1) 停止接收新的 MQ 消息 (pause / suspend consumer)
2) 等待现有消费线程把已经拉到的消息全部入队
3) 通知 Worker 优雅关闭：
     - 不再从队列拉取新任务
     - 处理完当前 localBuffer 后退出
4) 确认所有队列长度为 0、所有 Worker 结束
5) 释放 ES 客户端等资源
```

- 可以提供一个统一的 `shutdown()` 方法：
  - 先 `shutdown` RocketMQ Consumer；
  - 再 `shutdown` Worker 线程池，并 `awaitTermination` 一段时间；
  - 若超时仍有剩余，可将队列中剩余数据落地到本地文件，重启后再补偿入库。

### 10.6 监控与告警：安全的最后一层保障

- 关键监控指标：
  - 各队列长度、队列剩余容量；
  - 入队 / 出队 QPS；
  - Bulk 成功率、失败率、重试次数；
  - RocketMQ 重试次数、DLQ 消息数。
- 告警场景：
  - 某个队列持续接近满容量；
  - Bulk 失败率持续升高；
  - 某种日志类型长时间无消费（可能 Worker 异常）。

通过 **线程安全的数据结构 + 明确的 ACK 时机 + ES 幂等设计 + 优雅关闭 + 完整监控**，可以从端到端保证“写入队列和从队列拉取”的安全性与可观测性。
