AI生成
 
## 1. 讲一个你最熟悉或者最得意的项目
 
### 项目背景
 
- 公司有自营商城，经常有大促活动（如 618、品牌日），活动期间**流量瞬时飙升 10~20 倍**。 
- 之前的系统在活动开始的前几分钟经常出现：
  - 下单接口响应慢、超时；
  - 库存超卖，导致线下补救成本高；
  - 监控告警滞后，对问题定位困难。
- 我参与并主导了「活动购物链路高并发改造」项目，目标是：
  - 支撑活动峰值流量（预估 QPS 提升 10 倍以上）；
  - 保证**不超卖**、核心链路高可用；
  - 出了问题可以**快速定位**、可观测性好。
 
### 我的主要负责范围
 
1. 负责活动下单链路的技术方案设计和落地，包括：缓存、限流、异步化、分布式锁等。
2. 负责库存模块的改造：从「单点数据库扣减」升级为「缓存+数据库」的组合方案，并设计防超卖策略。
3. 牵头压测与容量评估，基于压测结果进行 JVM/SQL/中间件调优。
 
### 关键技术方案
 
1. **读多写少的缓存架构**
   - 将商品详情、活动价、库存快照等热点信息**提前预热到 Redis**，下单前端页面几乎不直接打数据库。
   - 对热点 Key 设计了**逻辑过期 + 异步刷新**，避免缓存击穿时瞬间打爆数据库。
 
2. **库存防超卖设计**
   - 引入基于 Redis 的**预扣减**：
     - 活动开始前把可售库存写入 Redis 计数器；
     - 下单时先对 Redis 做 `DECR` 校验是否还有库存，再进入后续业务逻辑；
     - 最终数据库以**异步批量写回**的方式与 Redis 对账，防止小误差。
   - 关键点：
     - 使用 `Lua` 脚本保证扣减和校验原子性；
     - 结合数据库乐观锁作为兜底，极端情况下仍能避免超卖。
 
3. **限流与降级**
   - 在网关层对下单接口做 **令牌桶限流**，防止瞬时流量超过系统极限；
   - 对非核心接口（如历史订单查询、推荐位等）设置降级策略，大促期间优先保障下单和支付；
   - 通过配置中心动态调节限流阈值，方便运营根据实时流量调整策略。
 
4. **异步化和削峰填谷**
   - 将一些耗时操作（如积分发放、优惠券记录、消息通知）通过 MQ 异步化；
   - 下单接口只做：参数校验 + 预扣库存 + 生成基础订单，尽量缩短同步链路。
 
5. **监控与压测**
   - 建立了从 Nginx、应用、Redis、数据库到 MQ 的**全链路监控**（QPS、RT、错误率、慢查询等）。
   - 编写压测脚本，模拟活动流量，对不同方案进行多轮压测，对比：
     - 改造前后 QPS、P95/P99 延迟；
     - Redis 命中率、数据库 CPU/IO 利用率。
 
### 项目效果
 
- 改造后经两次大促验证：
  - 峰值 QPS 提升了约 **8 倍**，下单接口 P99 延迟从 2s+ 降到几百毫秒以内；
  - 活动期间未再出现大规模超卖，只在极边界场景下出现个别订单需要手工处理；
  - 监控体系可以在问题发生后 **1~2 分钟内定位到瓶颈点**（是 Redis、DB 还是某个依赖服务）。
 
### 我的收获与反思
 
1. **系统性看待高并发问题**
   - 不再局限于某一层（例如只调 SQL 或只调 JVM），而是从「前端 → 网关 → 应用 → 缓存 → DB → MQ」全链路找瓶颈。
 
2. **对数据一致性有了更清晰的取舍**
   - 实时强一致 vs 最终一致，在库存、订单、营销等场景下要区分对待；
   - 通过预扣减 + 最终对账的方式在「用户体验」和「系统可承受的复杂度」之间找到平衡。
 
3. **工程落地能力提升**
   - 不是只停留在方案 PPT，而是从设计、开发、自测、联调到压测、上线全流程跟进；
   - 遇到问题（如 Redis 热点 Key、JVM Full GC）时，能结合监控和日志快速定位和修复。
 
> 面试时可以根据时间长短裁剪：
> - 若时间较短，重点讲背景 + 关键技术点 + 效果；
> - 若面试官愿意深挖，可以展开任意一个点（例如库存防超卖的细节、缓存方案、限流策略等）。
