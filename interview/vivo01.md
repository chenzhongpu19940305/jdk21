# vivo面试题汇总

## 1. 自我介绍+项目

**回答要点：**
- 简洁介绍个人背景：姓名、学历、工作年限、主要技术栈
- 重点介绍1-2个核心项目：
  - 项目背景和业务价值
  - 技术架构和选型理由
  - 个人在项目中的核心贡献
  - 遇到的技术难点和解决方案
  - 项目的成果和性能提升（用数据说话）
- 突出技术亮点：
  - 高并发、高可用系统设计经验
  - 性能优化成果
  - 解决过的复杂技术问题
- 表达对vivo的了解和加入意愿

---

## 2. 怎么设计高可用的系统,你会从什么方面考虑?

**回答要点：**
- **冗余设计**：
  - 多机房部署，避免单点故障
  - 服务多实例部署，负载均衡
  - 数据库主从复制，读写分离
- **故障隔离**：
  - 服务降级：非核心功能降级，保证核心功能
  - 熔断机制：快速失败，避免级联故障
  - 限流保护：防止流量过大打垮系统
- **监控告警**：
  - 实时监控系统健康状态
  - 关键指标告警（CPU、内存、QPS、错误率）
  - 日志聚合和分析
- **容错设计**：
  - 超时控制：避免长时间等待
  - 重试机制：指数退避重试
  - 优雅降级：返回默认值或缓存数据
- **数据一致性**：
  - 最终一致性方案
  - 分布式事务处理
  - 数据备份和恢复机制
- **自动化运维**：
  - 自动扩容缩容
  - 自动故障恢复
  - 灰度发布和回滚机制

---

## 3. spring aop ioc,控制反转是反转的什么?

**回答要点：**
- **IOC（Inversion of Control）控制反转**：
  - 传统方式：对象自己创建依赖对象（正转）
  - IOC方式：由容器创建和管理对象，对象被动接收依赖（反转）
  - **反转的是依赖对象的创建和获取的控制权**
- **IOC容器的作用**：
  - Bean的创建、初始化、销毁
  - 依赖注入（DI）：构造器注入、Setter注入、字段注入
  - 管理Bean的生命周期
- **AOP（Aspect-Oriented Programming）面向切面编程**：
  - 将横切关注点（日志、事务、安全等）从业务逻辑中分离
  - 通过代理模式实现：JDK动态代理、CGLIB代理
  - 核心概念：切面（Aspect）、连接点（JoinPoint）、切点（Pointcut）、通知（Advice）
- **IOC和AOP的关系**：
  - AOP依赖IOC容器管理切面Bean
  - AOP代理对象由IOC容器创建
  - 两者共同实现Spring的核心功能

---

## 4. jmm内存模型volatile关键字,i++会有并发问题吗?

**回答要点：**
- **JMM（Java Memory Model）内存模型**：
  - 定义了线程间共享变量的可见性规则
  - 主内存和工作内存的概念
  - happens-before规则保证内存可见性
- **volatile关键字特性**：
  - **可见性**：修改后立即刷新到主内存，其他线程可见
  - **有序性**：禁止指令重排序，保证有序性
  - **不保证原子性**：不能保证复合操作的原子性
- **i++的并发问题**：
  - `i++`是复合操作：读取i → 计算i+1 → 写回i
  - 三个步骤不是原子操作
  - 多线程并发执行会导致：
    - 丢失更新：多个线程读取到相同的值
    - 最终结果小于预期
- **解决方案**：
  - 使用`synchronized`同步块
  - 使用`AtomicInteger`等原子类
  - 使用`ReentrantLock`等锁机制
- **volatile适用场景**：
  - 单写多读场景
  - 状态标志位
  - 双重检查锁定模式

---

## 5. threadlocal如何实现多个线程访问同一个变量?

**回答要点：**
- **ThreadLocal的核心思想**：
  - 每个线程有独立的变量副本
  - 线程间互不干扰
  - 通过线程隔离实现线程安全
- **实现原理**：
  - Thread类内部有`ThreadLocalMap`属性
  - ThreadLocal作为Key，存储的值作为Value
  - 每个线程的ThreadLocalMap是独立的
- **数据结构**：
  ```java
  Thread -> ThreadLocalMap -> Entry[] 
  Entry: ThreadLocal<?> k, Object v
  ```
- **内存泄漏问题**：
  - ThreadLocalMap的Key是弱引用
  - 如果ThreadLocal被回收，Key变为null，但Value仍存在
  - 导致内存泄漏
- **解决方案**：
  - 使用完后调用`remove()`方法
  - 使用`try-finally`确保清理
- **应用场景**：
  - 线程上下文传递（用户信息、事务ID）
  - 避免参数传递
  - SimpleDateFormat等线程不安全类的线程安全使用

---

## 6. 设计一个RPC框架需要考虑哪些东西?

**回答要点：**
- **通信协议**：
  - 选择传输协议（TCP、HTTP/2、自定义协议）
  - 定义消息格式（协议头、消息体）
  - 支持多种序列化方式（Protobuf、JSON、Hessian）
- **服务注册与发现**：
  - 服务提供者注册到注册中心
  - 服务消费者从注册中心发现服务
  - 支持服务健康检查和动态上下线
  - 注册中心选型（Zookeeper、Nacos、Consul）
- **负载均衡**：
  - 多种策略：随机、轮询、加权、最少连接
  - 客户端负载均衡
  - 支持动态调整权重
- **容错机制**：
  - 超时控制：连接超时、读超时
  - 重试策略：快速失败、重试、失败安全
  - 熔断降级：失败率阈值、半开状态
- **网络通信**：
  - 使用Netty等NIO框架
  - 连接池管理：复用连接、心跳保活
  - 支持同步和异步调用
- **序列化**：
  - 高效的序列化算法
  - 支持多种序列化方式
  - 版本兼容性
- **线程模型**：
  - IO线程和业务线程分离
  - 线程池管理
  - 避免线程阻塞
- **监控和治理**：
  - 调用链追踪
  - 性能监控（QPS、延迟、错误率）
  - 动态配置下发
  - 服务治理（限流、降级）

---

## 7. HashMap的链表为什么要转换成红黑树?

**回答要点：**
- **HashMap的底层结构**：
  - JDK 1.8之前：数组 + 链表
  - JDK 1.8之后：数组 + 链表 + 红黑树
- **链表转红黑树的原因**：
  - **性能优化**：链表查询时间复杂度O(n)，红黑树O(log n)
  - **解决哈希冲突**：当链表长度过长时，查询效率低
  - **防止DoS攻击**：恶意构造大量哈希冲突的key，导致链表过长
- **转换条件**：
  - 链表长度 >= 8 时转换为红黑树
  - 红黑树节点数 <= 6 时转换回链表
  - 数组长度 >= 64 才会转换（否则先扩容）
- **为什么选择红黑树**：
  - 平衡二叉搜索树，保证最坏情况下的性能
  - 相比AVL树，插入删除操作更高效
  - 相比完全平衡树，维护成本更低
- **性能对比**：
  - 链表：O(n)查找，O(1)插入
  - 红黑树：O(log n)查找，O(log n)插入
  - 当节点数少时，链表性能更好；节点数多时，红黑树优势明显

---

## 8. MySQL中使用B+树的好处,B+树与B-树的区别?

**回答要点：**
- **B+树在MySQL中的优势**：
  - **适合磁盘存储**：节点大小接近页大小，减少IO次数
  - **范围查询高效**：叶子节点有序链表，范围查询只需遍历叶子节点
  - **查询稳定**：所有数据都在叶子节点，查询路径长度一致
  - **支持顺序访问**：叶子节点形成有序链表，适合排序和范围查询
- **B+树与B-树的区别**：
  - **数据存储位置**：
    - B-树：数据可以存储在非叶子节点
    - B+树：数据只存储在叶子节点
  - **叶子节点结构**：
    - B-树：叶子节点独立，无指针连接
    - B+树：叶子节点通过指针形成有序链表
  - **查询性能**：
    - B-树：可能在非叶子节点找到数据，查询不稳定
    - B+树：必须到叶子节点，查询路径长度固定
  - **范围查询**：
    - B-树：需要中序遍历，效率低
    - B+树：通过叶子节点链表顺序访问，效率高
  - **空间利用率**：
    - B-树：非叶子节点也存储数据，节点利用率高
    - B+树：非叶子节点只存储索引，可以存储更多键值
- **MySQL索引选择B+树的原因**：
  - 数据库主要操作是范围查询和排序
  - 磁盘IO是主要性能瓶颈
  - B+树更适合数据库的访问模式

---

## 9. 使用数据库的时候有哪些情况会导致索引失效呢?

**回答要点：**
- **在索引列上使用函数或表达式**：
  ```sql
  -- 失效
  WHERE DATE(create_time) = '2024-01-01'
  WHERE amount * 2 > 100
  
  -- 有效
  WHERE create_time >= '2024-01-01' AND create_time < '2024-01-02'
  WHERE amount > 50
  ```
- **隐式类型转换**：
  ```sql
  -- 失效（字符串列使用数字）
  WHERE phone = 13800138000
  
  -- 有效
  WHERE phone = '13800138000'
  ```
- **前导模糊查询**：
  ```sql
  -- 失效
  WHERE name LIKE '%张三'
  
  -- 可能失效（取决于优化器）
  WHERE name LIKE '%张三%'
  
  -- 有效
  WHERE name LIKE '张三%'
  ```
- **OR连接的条件**：
  ```sql
  -- 如果OR两边的列都有索引，可能使用索引合并
  -- 如果只有一边有索引，可能失效
  WHERE id = 1 OR name = 'test'
  ```
- **NOT、!=、<>操作符**：
  ```sql
  -- 通常不使用索引
  WHERE status != 1
  WHERE status <> 1
  WHERE NOT status = 1
  ```
- **联合索引不遵循最左前缀原则**：
  ```sql
  -- 索引：(a, b, c)
  -- 失效
  WHERE b = 1 AND c = 2
  
  -- 有效
  WHERE a = 1
  WHERE a = 1 AND b = 2
  ```
- **索引列参与计算**：
  ```sql
  -- 失效
  WHERE id + 1 = 100
  
  -- 有效
  WHERE id = 99
  ```
- **使用IS NULL或IS NOT NULL**：
  ```sql
  -- 可能不使用索引（取决于NULL值比例）
  WHERE name IS NULL
  ```
- **优化器认为全表扫描更快**：
  - 数据量小
  - 索引选择性低
  - 统计信息不准确

---

## 10. 缓存是如何刷新的,怎么保证缓存刷新成功?

**回答要点：**
- **缓存刷新策略**：
  - **主动刷新**：数据更新时同步更新缓存
  - **定时刷新**：定时任务批量刷新缓存
  - **被动刷新**：缓存过期后重新加载
  - **事件驱动**：监听数据变更事件，触发缓存刷新
- **刷新方式**：
  - **Cache Aside（旁路缓存）**：
    - 更新：先更新数据库，再删除缓存
    - 查询：先查缓存，未命中查数据库并写入缓存
  - **Write Through（写穿透）**：
    - 更新：同时更新数据库和缓存
  - **Write Back（写回）**：
    - 更新：只更新缓存，异步批量写回数据库
- **保证刷新成功的机制**：
  - **重试机制**：
    - 缓存更新失败时重试
    - 指数退避重试策略
    - 最大重试次数限制
  - **消息队列保证**：
    - 数据变更发送到MQ
    - 消费者处理缓存刷新
    - 支持消息重试和死信队列
  - **双写策略**：
    - 同时写入多个缓存实例
    - 至少一个成功即认为成功
  - **版本号机制**：
    - 缓存中存储数据版本号
    - 数据更新时版本号递增
    - 查询时比较版本号，不一致则刷新
- **监控和告警**：
  - 监控缓存刷新成功率
  - 刷新失败时告警
  - 记录刷新日志便于排查
- **降级方案**：
  - 缓存刷新失败时，使用旧缓存
  - 设置缓存过期时间作为兜底
  - 关键数据支持手动刷新

---

## 11. volatile有哪几个特性?

**回答要点：**
- **可见性（Visibility）**：
  - 修改volatile变量后，立即刷新到主内存
  - 其他线程读取时，从主内存重新加载
  - 保证多线程间变量的可见性
- **有序性（Ordering）**：
  - 禁止指令重排序
  - 通过内存屏障（Memory Barrier）实现
  - 保证volatile变量前后的指令不会被重排序
- **不保证原子性（Non-atomicity）**：
  - volatile不能保证复合操作的原子性
  - 例如：`i++`、`count = count + 1`等操作
  - 需要配合synchronized或原子类使用
- **happens-before规则**：
  - volatile写操作happens-before后续的volatile读操作
  - 保证内存可见性和有序性
- **内存屏障**：
  - **Load Barrier**：读屏障，保证读操作不会被重排序到屏障之后
  - **Store Barrier**：写屏障，保证写操作不会被重排序到屏障之前
- **适用场景**：
  - 状态标志位（boolean flag）
  - 单写多读场景
  - 双重检查锁定（Double-Checked Locking）
- **性能考虑**：
  - volatile读写的性能开销比普通变量稍高
  - 但比synchronized锁的开销小得多
  - 适合读多写少的场景

---

## 12. 数据到ES是怎么流转的?宁德时代 CATL

**回答要点：**
- **数据流转架构**：
  - **数据源**：业务数据库（MySQL、Oracle等）
  - **数据采集**：Canal、Maxwell、Debezium等CDC工具
  - **消息队列**：Kafka、RocketMQ等
  - **数据处理**：Flink、Spark Streaming等流处理框架
  - **数据存储**：Elasticsearch
- **典型流转流程**：
  1. **数据变更捕获**：
     - 通过数据库binlog捕获数据变更
     - Canal等工具解析binlog
     - 转换为结构化消息
  2. **消息队列缓冲**：
     - 变更事件发送到Kafka
     - 实现解耦和削峰
     - 支持多消费者订阅
  3. **数据转换处理**：
     - Flink消费Kafka消息
     - 数据清洗、转换、聚合
     - 构建ES索引结构
  4. **写入Elasticsearch**：
     - 批量写入ES
     - 使用Bulk API提高性能
     - 支持索引模板和动态映射
- **宁德时代（CATL）场景特点**：
  - **工业物联网数据**：设备监控、生产数据
  - **时序数据**：时间序列数据量大
  - **实时性要求**：需要实时监控和告警
  - **数据量巨大**：TB级甚至PB级数据
- **优化策略**：
  - **批量写入**：使用Bulk API，批量大小优化
  - **索引分片**：合理设置分片数和副本数
  - **索引生命周期管理**：热温冷数据分层
  - **数据压缩**：启用压缩减少存储
  - **异步处理**：异步写入，不阻塞业务
- **数据一致性**：
  - 最终一致性模型
  - 通过版本号处理并发更新
  - 支持数据修复和补偿机制
- **监控和运维**：
  - 监控数据流转延迟
  - 监控ES集群健康状态
  - 告警机制：数据积压、写入失败等

---

## 补充说明

- 以上答案仅供参考，实际面试中需要结合具体项目经验
- 建议准备具体的代码示例和项目案例
- 关注vivo的业务场景，结合业务回答问题
- 保持逻辑清晰，表达流畅


